# Optimization_And_Uncertainty

#In this class, we explored ways of optimizing systems and environments under uncertainty. We first focussed on Stochastic Satisfiability problems, which we solved using a DPLL algorithm. We then learned about Bayesian Statistics, completing classwork and homework assignments. Lastly, we focussed on reinforcement learning, an area of machine learning. In our final project, we utilized Markov Decision Processes (MDPs) to model and solve an agent in an uncertain environment, but with full observability. The agent had to optimally move from a starting point to an end point in a board with positive and negative rewards. The agent moved with a certain transition probability as well. Using the markov property and the bellman equation, we iteratively determined the optimal path of the agent with value iteration and policy iteration.
